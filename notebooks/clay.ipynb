{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ba461-1412-4a31-94f6-5d2bd1c62ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from claymodel.module import ClayMAEModule\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from pyproj import Transformer\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import copy\n",
    "from torchvision.transforms import v2\n",
    "import math\n",
    "from estuary.util import contrast_stretch\n",
    "from einops import rearrange\n",
    "from sklearn import decomposition, svm\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_recall_fscore_support, f1_score, balanced_accuracy_score\n",
    "from estuary.clay.data import EstuaryDataModule\n",
    "from estuary.clay.module import EstuaryModule\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26680942-74dc-42c7-b6b9-6f8d26bdb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = ClayMAEModule.load_from_checkpoint(\n",
    "    \"/Users/kyledorman/data/models/clay/clay-v1.5.ckpt\",\n",
    "    metadata_path=\"/Users/kyledorman/data/models/clay/metadata.yaml\",\n",
    "    mask_ratio=0.0,\n",
    "    shuffle=False,\n",
    ")\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4aae7-c108-45e6-90e0-e425ed04be20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load sensor metadata\n",
    "with open(\"/Users/kyledorman/data/models/clay/metadata.yaml\", \"r\") as f:\n",
    "    metadata = yaml.safe_load(f)\n",
    "\n",
    "channel_4_band_order = [\n",
    "    'blue',\n",
    "    'green',\n",
    "    'red',\n",
    "    'nir',\n",
    "]\n",
    "planetscope = metadata['planetscope-sr']\n",
    "metadata['planetscope-sr-4'] = {}\n",
    "metadata['planetscope-sr-4']['band_order'] = channel_4_band_order\n",
    "metadata['planetscope-sr-4']['rgb_indices'] = [3, 2, 1]\n",
    "metadata['planetscope-sr-4']['gsd'] = 3\n",
    "bands = {}\n",
    "for k, vs in planetscope['bands'].items():\n",
    "    vs4 = {kk: vv for kk, vv in vs.items() if kk in channel_4_band_order}\n",
    "    bands[k] = vs4\n",
    "metadata['planetscope-sr-4']['bands'] = bands\n",
    "\n",
    "metadata['planetscope-sr-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c01437-6ceb-427f-b424-2c3b3a2cf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_latlon(lat, lon):\n",
    "    \"\"\"\n",
    "    Normalize latitude and longitude to a range between -1 and 1.\n",
    "\n",
    "    Parameters:\n",
    "    lat (float): Latitude value.\n",
    "    lon (float): Longitude value.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Normalized latitude and longitude values.\n",
    "    \"\"\"\n",
    "    lat = lat * np.pi / 180\n",
    "    lon = lon * np.pi / 180\n",
    "\n",
    "    return (math.sin(lat), math.cos(lat)), (math.sin(lon), math.cos(lon))\n",
    "\n",
    "def normalize_timestamp(date):\n",
    "    week = date.isocalendar().week * 2 * np.pi / 52\n",
    "    hour = date.hour * 2 * np.pi / 24\n",
    "\n",
    "    return (math.sin(week), math.cos(week)), (math.sin(hour), math.cos(hour))\n",
    "\n",
    "def prep_datacube(image, lat, lon, date):\n",
    "    \"\"\"\n",
    "    Prepare a data cube for model input.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.array): The input image array.\n",
    "    lat (float): Latitude value for the location.\n",
    "    lon (float): Longitude value for the location.\n",
    "\n",
    "    Returns:\n",
    "    dict: Prepared data cube with normalized values and embeddings.\n",
    "    \"\"\"\n",
    "    md = metadata['planetscope-sr-4']\n",
    "\n",
    "    # Extract mean, std, and wavelengths from metadata\n",
    "    mean = []\n",
    "    std = []\n",
    "    waves = []\n",
    "    bands = md['band_order']\n",
    "    for band_name in bands:\n",
    "        mean.append(md['bands']['mean'][band_name])\n",
    "        std.append(md['bands']['std'][band_name])\n",
    "        waves.append(md['bands']['wavelength'][band_name] * 1000)\n",
    "\n",
    "    transform = v2.Compose(\n",
    "        [\n",
    "            v2.Resize(size=(128, 128), interpolation=3),\n",
    "            v2.Normalize(mean=mean, std=std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Prep datetimes embedding\n",
    "    times = normalize_timestamp(date)\n",
    "    week_norm = times[0]\n",
    "    hour_norm = times[1]\n",
    "\n",
    "    # Prep lat/lon embedding\n",
    "    latlons = normalize_latlon(lat, lon)\n",
    "    lat_norm = latlons[0]\n",
    "    lon_norm = latlons[1]\n",
    "\n",
    "    # Prep pixels\n",
    "    pixels = torch.from_numpy(image.astype(np.float32))\n",
    "    pixels = transform(pixels)\n",
    "    pixels = pixels.unsqueeze(0)\n",
    "\n",
    "    # Prepare additional information\n",
    "    return {\n",
    "        \"pixels\": pixels,\n",
    "        \"time\": torch.tensor(\n",
    "            np.hstack((week_norm, hour_norm)),\n",
    "            dtype=torch.float32,\n",
    "        ).unsqueeze(0),\n",
    "        \"latlon\": torch.tensor(\n",
    "            np.hstack((lat_norm, lon_norm)), dtype=torch.float32\n",
    "        ).unsqueeze(0),\n",
    "        \"waves\": torch.tensor(waves),\n",
    "        \"gsd\": torch.tensor(md['gsd'] * 2).unsqueeze(0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98df1e-3fdb-4c03-ae95-92c310103aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube = prep_datacube(data, *cent_g, dt)\n",
    "with torch.no_grad():\n",
    "    unmsk_patch, unmsk_idx, msk_idx, msk_matrix = model.model.encoder(datacube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923947d0-fc22-4d86-8182-40f95570a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first embedding is the class token, which is the overall single embedding.\n",
    "unmsk_patch[:, 0, :].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2850ff3-ce81-4682-be52-b60ea630156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_embedder_cpu = torch.export.load(\"/Users/kyledorman/data/models/clay/clay-v1.5-encoder_256.pt2\").module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fa23b-6cf0-423f-9d25-87166b5bb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "datacube = prep_datacube(data, *cent_g, dt)\n",
    "with torch.no_grad():\n",
    "    embeddings = ep_embedder_cpu(datacube)\n",
    "datacube[\"pixels\"].shape, embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a819e66-8bf9-4df7-aeb6-a8dcf8d07e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 32\n",
    "\n",
    "embed = rearrange(\n",
    "    unmsk_patch[:, 1:, :].detach().cpu().numpy(), \"b (h w) d-> b d h w\", h=size, w=size\n",
    ")\n",
    "embed = embed[0]\n",
    "rows = 4\n",
    "cols = 4\n",
    "fig, axs = plt.subplots(cols, cols, figsize=(20, 20))\n",
    "\n",
    "# idxes = np.random.choice(unmsk_patch.shape[2], rows * cols - 1, replace=False)\n",
    "\n",
    "for idx, ax in zip(idxes, axs.flatten()[1:]):\n",
    "    ax.imshow(embed[idx], cmap=\"bwr\")\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(idx)\n",
    "\n",
    "ax = axs.flatten()[0]\n",
    "dd = np.log10(1 + data[[3, 2, 1]].clip(1, 2000))\n",
    "dd = contrast_stretch(dd)\n",
    "show(dd, ax=ax)\n",
    "ax.set_axis_off()\n",
    "ax.set_title(idx)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35d135-03d3-4120-ade5-86b5abd27299",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/Users/kyledorman/data/estuary/label_studio/00025/labels.csv\")\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96dace-e938-4302-bbb1-90b754eb2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = EstuaryModule.load_from_checkpoint(\n",
    "    \"/Users/kyledorman/data/results/estuary/train/20250805-205230/checkpoints/last.ckpt\", \n",
    "    strict=False)\n",
    "module.conf.holdout_region = None\n",
    "module = module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c5630-db94-44d9-8bd7-871ffe2322af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = EstuaryDataModule(module.conf)\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134c23f-fe03-45f6-82c6-c7b41226dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dm.train_dataloader()\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "for batch, blabel in tqdm.tqdm(dl, total=len(dl)):\n",
    "    for k in batch.keys():\n",
    "        batch[k] = batch[k].to(module.device)\n",
    "    pred_batch = module.forward(batch)\n",
    "    preds.extend(pred_batch.argmax(axis=1).detach().cpu().numpy().tolist())\n",
    "    labels.extend(blabel.detach().cpu().numpy().tolist())\n",
    "\n",
    "accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885ef03-dce7-4fb4-9e00-ade9897bdf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dm.val_dataloader()\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "for batch, blabel in tqdm.tqdm(dl, total=len(dl)):\n",
    "    for k in batch.keys():\n",
    "        batch[k] = batch[k].to(module.device)\n",
    "    pred_batch = module.forward(batch)\n",
    "    preds.extend(pred_batch.argmax(axis=1).detach().cpu().numpy().tolist())\n",
    "    labels.extend(blabel.detach().cpu().numpy().tolist())\n",
    "\n",
    "accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e2132-d106-47d9-81be-c8496f5badfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dm.test_dataloader()\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "for batch, blabel in tqdm.tqdm(dl, total=len(dl)):\n",
    "    for k in batch.keys():\n",
    "        batch[k] = batch[k].to(module.device)\n",
    "    pred_batch = module.forward(batch)\n",
    "    preds.extend(pred_batch.argmax(axis=1).detach().cpu().numpy().tolist())\n",
    "    labels.extend(blabel.detach().cpu().numpy().tolist())\n",
    "\n",
    "accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c070c8-e705-4962-89a5-581cee44b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = dm.test_ds.df\n",
    "X_test = []\n",
    "for _, row in label_df.iterrows():\n",
    "    pth = Path(row.source_jpeg)\n",
    "    emb_pth = pth.parent.parent / \"embeddings\" / f\"{pth.stem}.npy\"\n",
    "    emb = np.load(emb_pth)\n",
    "    X_test.append(emb)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(label_df.label_idx.tolist())\n",
    "\n",
    "label_df = dm.train_ds.df\n",
    "X_train = []\n",
    "for _, row in label_df.iterrows():\n",
    "    pth = Path(row.source_jpeg)\n",
    "    emb_pth = pth.parent.parent / \"embeddings\" / f\"{pth.stem}.npy\"\n",
    "    emb = np.load(emb_pth)\n",
    "    X_train.append(emb)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(label_df.label_idx.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e85216-4a2a-4558-951e-bd084f20b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "# clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict classes on test set\n",
    "svn_pred = clf.predict(X_test)\n",
    "y_test = dm.test_ds.df.label_idx\n",
    "# Perfect match for SVM\n",
    "match = np.sum(y_test == svn_pred)\n",
    "print(f\"Matched {match} out of {len(X_test)} correctly\")\n",
    "\n",
    "_ = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, \n",
    "    svn_pred, \n",
    "    labels=list(range(len([\"open\", \"closed\"]))),\n",
    "    display_labels=[\"open\", \"closed\"],\n",
    ")\n",
    "\n",
    "print(\"Accuracy\", accuracy_score(y_test, svn_pred))\n",
    "prfs = precision_recall_fscore_support(y_test, svn_pred, average='macro')\n",
    "print(\"F1\", round(prfs[2], 3))\n",
    "print(\"Precision\", round(prfs[0], 3))\n",
    "print(\"Recall\", round(prfs[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e828bd-7615-404f-8da9-4a464a728da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(\n",
    "    list(zip(\n",
    "        preds,\n",
    "        svn_pred,\n",
    "        dm.test_ds.df.label_idx.tolist(),\n",
    "        dm.test_ds.df.region.tolist(),\n",
    "        dm.test_ds.df.source_jpeg.tolist(),\n",
    "    )), \n",
    "    columns=['dnn', 'svn', 'label', 'region', 'source_jpeg']\n",
    ")\n",
    "# Define a function to compute accuracy per group\n",
    "def compute_accuracy(group, pred_col):\n",
    "    return balanced_accuracy_score(group['label'], group[pred_col])\n",
    "\n",
    "# Group by region and compute accuracy\n",
    "dnn_acc_by_region = pred_df.groupby('region').apply(lambda g: compute_accuracy(g, 'dnn'))\n",
    "svn_acc_by_region = pred_df.groupby('region').apply(lambda g: compute_accuracy(g, 'svn'))\n",
    "closed_pct = pred_df.groupby('region').apply(lambda g: g.label.sum() / g.label.count())\n",
    "\n",
    "# Combine into a DataFrame for display\n",
    "acc_df = pd.DataFrame({\n",
    "    'dnn': dnn_acc_by_region,\n",
    "    'svn': svn_acc_by_region,\n",
    "    \"closed_pct\": closed_pct,\n",
    "}).reset_index()\n",
    "\n",
    "# Show the result\n",
    "region_stats = acc_df.drop(columns=\"svn\").rename(columns={\"dnn\": \"accuracy\"}).sort_values(by=\"region\").set_index(\"region\")\n",
    "print(region_stats.round(2))\n",
    "region_stats.round(2).to_csv(\"/Users/kyledorman/data/estuary/display/per_region_results.csv\")\n",
    "\n",
    "print(\"dnn\", balanced_accuracy_score(pred_df.label, pred_df.dnn))\n",
    "print(\"svn\", balanced_accuracy_score(pred_df.label, pred_df.svn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c50ce4-f2e7-40a3-b1fc-3f830d70b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"/Users/kyledorman/data/estuary/label_studio/00025/labels.csv\")\n",
    "for r, g in labels.groupby(\"region\"):\n",
    "    print(r, round((g.label == \"closed\").sum() / len(g.label), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007f4d46-18f5-4e7f-a658-6034c268fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "aaa = pred_df[(pred_df.dnn != pred_df.label)]\n",
    "\n",
    "rows = 3\n",
    "cols = 4\n",
    "fig, axs = plt.subplots(cols, cols, figsize=(15, 15))\n",
    "\n",
    "for (idx, row), ax in zip(aaa.iterrows(), axs.flatten()):\n",
    "    ax.imshow(Image.open(row.source_jpeg))\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(f\"{row.region} pred={module.conf.classes[row.dnn]} label={module.conf.classes[row.label]}\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a54588-145e-49ee-bec7-552dbee18e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
