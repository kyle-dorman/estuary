{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e32b2f-2b1b-4a60-990d-710382d94f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503e454-e0ec-4acd-9cb8-d07c651be24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import tqdm\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import datetime\n",
    "\n",
    "from estuary.util import false_color, masked_contrast_stretch, broad_band\n",
    "from estuary.model.data import parse_dt_from_pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef70d1-a699-4bb0-b56e-793eef04edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df = pd.read_csv(\"/Volumes/x10pro/estuary/skysat/labels.csv\")\n",
    "ss_df[\"acquired\"] = ss_df.source_tif.apply(lambda a: parse_dt_from_pth(Path(a)))\n",
    "ss_df = ss_df.sort_values([\"region\", \"acquired\"]).reset_index(drop=True)\n",
    "ss_df[\"simple_label\"] = ss_df.label.apply(lambda a: int(\"open\" in a))\n",
    "ss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e592c3f-940e-4b2d-b234-36280a5ea302",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_df = pd.read_csv(\"/Volumes/x10pro/estuary/dove/labels.csv\")\n",
    "dd_df[\"acquired\"] = dd_df.source_tif.apply(lambda a: parse_dt_from_pth(Path(a)))\n",
    "dd_df = dd_df.sort_values([\"region\", \"acquired\"]).reset_index(drop=True)\n",
    "dd_df[\"simple_label\"] = dd_df.label.apply(lambda a: int(\"open\" in a))\n",
    "dd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4f172-a747-4b51-a6d4-0f821263fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = pd.Timedelta(\"14h\")\n",
    "\n",
    "# cross-join within region, then filter by window\n",
    "tmp = dd_df.merge(ss_df, on=\"region\", suffixes=(\"_dd\", \"_ss\"))\n",
    "mask = (tmp[\"acquired_dd\"] >= tmp[\"acquired_ss\"] - tol) & (\n",
    "    tmp[\"acquired_dd\"] <= tmp[\"acquired_ss\"] + tol\n",
    ")\n",
    "pairs = tmp.loc[mask].sort_values([\"region\", \"acquired_dd\", \"acquired_ss\"])\n",
    "\n",
    "pairs[\"match\"] = pairs.label_dd == pairs.label_ss\n",
    "pairs[\"simple_match\"] = pairs.simple_label_dd == pairs.simple_label_ss\n",
    "\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a9398-a471-422c-b3e1-257c3652dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.match.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f7ad2-4d45-4a05-9ba1-19b35aee5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.simple_match.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f6b9b-ea4c-4421-b8b8-f9aa9fba970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed73cd-5fe3-49c9-9f8e-5694730a5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clear_dfs = []\n",
    "all_dfs = []\n",
    "all_to_download_dfs = []\n",
    "\n",
    "def parse_dt_from_asset_id(asset_id: str) -> datetime.datetime:\n",
    "    \"\"\"Parse acquisition datetime from file stem prefix YYYYMMDD_HHMMSS_*\"\"\"\n",
    "    datetime_str = \"_\".join(asset_id.split(\"_\")[:2])\n",
    "    date_format = \"%Y%m%d_%H%M%S\"\n",
    "    return datetime.datetime.strptime(datetime_str, date_format)\n",
    "\n",
    "for region_p in Path(\"/Volumes/x10pro/estuary/ca_grids\").iterdir():\n",
    "    region = region_p.stem\n",
    "    for year in range(2017, 2026):\n",
    "        for month in range(1, 13):\n",
    "            for dove in [\"superdove\", \"dove\"]:\n",
    "                pth = Path(f\"/Volumes/x10pro/estuary/ca_all/{dove}/results\") / str(year) / str(month) / str(region) / \"clear_images_to_download.csv\"\n",
    "                if not pth.exists():\n",
    "                    continue\n",
    "                df = pd.read_csv(pth)\n",
    "                df[\"dove\"] = dove\n",
    "                df[\"region\"] = int(region)\n",
    "                df[\"year\"] = int(year)\n",
    "                df[\"month\"] = int(month)\n",
    "                df[\"acquired\"] = df.asset_id.apply(parse_dt_from_asset_id) \n",
    "\n",
    "                all_clear_dfs.append(df)\n",
    "\n",
    "                pth = Path(f\"/Volumes/x10pro/estuary/ca_all/{dove}/results\") / str(year) / str(month) / str(region) / \"images_to_download.csv\"\n",
    "                if not pth.exists():\n",
    "                    continue\n",
    "                ddf = pd.read_csv(pth)\n",
    "                ddf[\"dove\"] = dove\n",
    "                ddf[\"region\"] = int(region)\n",
    "                ddf[\"year\"] = int(year)\n",
    "                ddf[\"month\"] = int(month)\n",
    "                ddf[\"acquired\"] = df.asset_id.apply(parse_dt_from_asset_id)\n",
    "                downloaded_asset_ids = ddf.asset_id.tolist()\n",
    "                ddf = ddf[ddf.asset_id.isin(df.asset_id)].copy()\n",
    "\n",
    "                all_dfs.append(ddf)\n",
    "\n",
    "                all_to_download_dfs.append(df[~df.asset_id.isin(downloaded_asset_ids)].copy())\n",
    "\n",
    "clear_df = pd.concat(all_clear_dfs)\n",
    "clear_df = clear_df.drop(columns=['ordered_idx', 'capture_datetime'])\n",
    "\n",
    "available_df = pd.concat(all_dfs)\n",
    "available_df = available_df.drop(columns=['ordered_idx', 'capture_datetime'])\n",
    "\n",
    "to_download_df = pd.concat(all_to_download_dfs)\n",
    "\n",
    "print(len(clear_df), len(available_df))\n",
    "\n",
    "clear_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff26a2-908c-4b98-8d01-5c31af412f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df = pd.read_csv(\"/Volumes/x10pro/estuary/skysat/labels.csv\")\n",
    "ss_df[\"acquired\"] = ss_df.source_tif.apply(lambda a: parse_dt_from_pth(Path(a)))\n",
    "ss_df[\"month\"] = ss_df.acquired.dt.month\n",
    "ss_df[\"year\"] = ss_df.acquired.dt.year\n",
    "ss_df = ss_df.drop(columns=['source_jpeg'])\n",
    "ss_df = ss_df[ss_df.label != \"unsure\"].copy()\n",
    "ss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1c5fb-382c-4586-ae38-05c29819a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = clear_df.merge(ss_df, on=\"region\", suffixes=(\"_dd\", \"_ss\"))\n",
    "tmp[\"acquired_diff\"] = (tmp.acquired_dd - tmp.acquired_ss).abs()\n",
    "tol = pd.Timedelta(\"10h\")\n",
    "mask = (tmp[\"acquired_dd\"] >= tmp[\"acquired_ss\"] - tol) & (\n",
    "    tmp[\"acquired_dd\"] <= tmp[\"acquired_ss\"] + tol\n",
    ")\n",
    "dove_pairs = tmp.loc[mask].sort_values([\"region\", \"acquired_dd\", \"acquired_ss\"])\n",
    "\n",
    "dove_pairs = dove_pairs.drop(columns=[\"year_ss\", \"month_ss\"]).rename(\n",
    "    columns={\"year_dd\": \"year\", \"month_dd\": \"month\"}\n",
    ")\n",
    "\n",
    "dove_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683aa8e6-351e-4df0-837b-9aa35d5c270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip the _3B_udm2 from the file name\n",
    "# e.g. 20230901_182511_53_2486_3B_udm2.tif\n",
    "def cleaned_asset_id(filename: str) -> str:\n",
    "    filepath = Path(filename)\n",
    "    return filepath.stem.split(\"_3B_\")[0]\n",
    "\n",
    "dove_labels = pd.read_csv(\"/Volumes/x10pro/estuary/dove/labels.csv\")\n",
    "dove_labels[\"acquired\"] = pd.to_datetime(dove_labels[\"acquired\"], errors=\"coerce\")\n",
    "dove_labels[\"asset_id\"] = dove_labels.source_tif.apply(cleaned_asset_id)\n",
    "dove_labels[\"year\"] = dove_labels.acquired.dt.year\n",
    "dove_labels[\"month\"] = dove_labels.acquired.dt.month\n",
    "dove_labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dccf584-8a25-49a2-99d8-788003687c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudy_downloads = {}\n",
    "clear_downloads = {}\n",
    "for region_p in Path(\"/Volumes/x10pro/estuary/ca_grids\").iterdir():\n",
    "    region = region_p.stem\n",
    "    for year in range(2017, 2026):\n",
    "        for month in range(1, 13):\n",
    "            for dove in [\"superdove\", \"dove\"]:\n",
    "                pth = Path(f\"/Volumes/x10pro/estuary/ca_all/{dove}/results\") / str(year) / str(month) / str(region) / \"filtered_search_results.json\"\n",
    "                if not pth.exists():\n",
    "                    continue\n",
    "                with open(pth) as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                cloudy = []\n",
    "                clear = []\n",
    "                for d in data:\n",
    "                    asset_id = d['id']\n",
    "                    visible_pct = d['properties']['visible_percent']\n",
    "                    clear_pct = d['properties']['clear_percent']\n",
    "                    anomalous_pixels = d['properties'][\"anomalous_pixels\"]\n",
    "                    visible_confidence_percent = d['properties']['visible_confidence_percent']\n",
    "                    if visible_pct == 0:\n",
    "                        cloudy.append(asset_id)\n",
    "                    elif clear_pct == 100 and visible_pct == 100 and anomalous_pixels < 0.009 and visible_confidence_percent > 80:\n",
    "                        clear.append(asset_id)\n",
    "                if len(cloudy):\n",
    "                    cloudy_downloads[(region, year, month, dove)] = cloudy\n",
    "                if len(clear):\n",
    "                    clear_downloads[(region, year, month, dove)] = clear\n",
    "\n",
    "len(cloudy_downloads), len(clear_downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff56e7d7-bd2d-49d6-ae0a-a335134b83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(source_base / \"test.tif\").parents[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91597787-eaac-4b8c-9ad4-73d7b08de865",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(Path(\"/Volumes/x10pro/estuary/ca_all/\").glob(\"*ove/results/*/*/*/files/*_SR_*.tif\"))\n",
    "ff = {(p.parents[3].stem, p.parents[2].stem, p.parents[1].stem, cleaned_asset_id(p)): p for p in files}\n",
    "len(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067955c8-d6bb-49b7-af53-38971130dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clears = []\n",
    "for (region, year, month, dove), asset_ids in clear_downloads.items():\n",
    "    for asset_id in asset_ids:\n",
    "        key = (str(year), str(month), str(region), asset_id)\n",
    "        filename = ff.get(key)\n",
    "        if filename is None:\n",
    "            continue\n",
    "            # print((region, year, month, dove), asset_id)\n",
    "        clears.append({\n",
    "            \"region\": int(region),\n",
    "            \"year\": int(year),\n",
    "            \"month\": int(month),\n",
    "            \"instrument\": dove,\n",
    "            \"source_tif\": filename,\n",
    "            \"acquired\": parse_dt_from_asset_id(asset_id),\n",
    "            \"asset_id\": asset_id,\n",
    "        })\n",
    "\n",
    "clear_labels_df = pd.DataFrame(clears)\n",
    "print(len(clear_labels_df))\n",
    "clear_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b42ac-4c6b-44a6-987a-cca1631c41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_labels_df.to_csv(\"/Volumes/x10pro/estuary/quality_dataset/possible_files.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8d05a-f17c-47bf-a3df-a82df3ca10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estuary.util import masked_contrast_stretch\n",
    "import cv2\n",
    "import pywt\n",
    "\n",
    "def denoise_mild(y: np.ndarray, method: str = \"gaussian\") -> np.ndarray:\n",
    "    if method == \"bilateral\":\n",
    "        # Bilateral: preserve edges a bit; parameters are mild\n",
    "        # diameter 5, sigmaColor .1, sigmaSpace 3 (on [0,1] scale)\n",
    "        return cv2.bilateralFilter(y, d=5, sigmaColor=0.1, sigmaSpace=3)\n",
    "    # Gaussian mild blur\n",
    "    return cv2.GaussianBlur(y, (5,5), 0.8)\n",
    "\n",
    "def robust_std(x: np.ndarray) -> float:\n",
    "    # MAD-based robust std\n",
    "    med = np.nanmedian(x)\n",
    "    mad = np.nanmedian(np.abs(x - med))\n",
    "    return float(1.4826 * mad)\n",
    "\n",
    "def gradient_mag(y: np.ndarray) -> np.ndarray:\n",
    "    gx = cv2.Sobel(y, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(y, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    return np.sqrt(gx*gx + gy*gy)\n",
    "\n",
    "def sharpness_score(x: np.ndarray) -> float:\n",
    "    x_blur = cv2.GaussianBlur(x, (5,5), 1.0)\n",
    "    lap = cv2.Laplacian(x_blur, cv2.CV_32F)\n",
    "    return float(lap.var())\n",
    "\n",
    "def noise_score(x: np.ndarray) -> float:\n",
    "    x_blur = cv2.GaussianBlur(x, (5,5), 1.0)\n",
    "    residual = x - x_blur\n",
    "    med = np.median(residual)\n",
    "    mad = np.median(np.abs(residual - med))\n",
    "    return 1.4826 * mad  # robust Ïƒ estimate\n",
    "\n",
    "clear_labels_df[\"sharp\"] = 0.0\n",
    "clear_labels_df[\"noise\"] = 0.0\n",
    "\n",
    "\n",
    "import pandas as pd, scipy.stats as st\n",
    "from estuary.util.constants import FALSE_COLOR_4, FALSE_COLOR_8\n",
    "\n",
    "for idx, row in clear_labels_df.iterrows():\n",
    "\n",
    "    with rasterio.open(row.source_tif) as src:\n",
    "        data = src.read()\n",
    "        nodata = src.read(1, masked=True).mask\n",
    "        if len(data) == 4:\n",
    "            rgb_idx = FALSE_COLOR_4\n",
    "        else:\n",
    "            rgb_idx = FALSE_COLOR_8\n",
    "    \n",
    "        r, g, b = [data[i] for i in rgb_idx]\n",
    "        luma = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        img = masked_contrast_stretch(luma, ~nodata)\n",
    "        clear_labels_df.loc[idx, \"sharp\"] = sharpness_score(img)\n",
    "        clear_labels_df.loc[idx, \"noise\"] = noise_score(img)\n",
    "\n",
    "\n",
    "# z-score each to normalize\n",
    "clear_labels_df[\"sharp_z\"] = st.zscore(clear_labels_df[\"sharp\"])\n",
    "clear_labels_df[\"noise_z\"] = st.zscore(clear_labels_df[\"noise\"])\n",
    "clear_labels_df[\"clarity_score\"] = clear_labels_df[\"sharp_z\"] - clear_labels_df[\"noise_z\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed1dbc-c573-45bb-bf5c-3a7bf2a8c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "\n",
    "deduped = clear_labels_df.sort_values(\n",
    "    by=[\"region\", \"year\", \"month\", \"clarity_score\"], ascending=False\n",
    ").drop_duplicates(subset=[\"region\", \"year\", \"month\"])\n",
    "\n",
    "top_lap = (\n",
    "    deduped\n",
    "    .sort_values([\"region\", \"clarity_score\"], ascending=[True, False])\n",
    "    .groupby(\"region\", group_keys=False)\n",
    "    .head(N)\n",
    ")\n",
    "\n",
    "top_lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff959c-c391-4d20-be5c-a7c665abca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_lap.drop(columns=['lap']).to_csv(\"/Volumes/x10pro/estuary/quality_dataset/clear.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff071191-7f95-4de1-8151-833ba553045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = top_lap.iloc[197].source_tif\n",
    "with rasterio.open(a) as src:\n",
    "    plt.figure()\n",
    "    plt.imshow(false_color(src.read(), src.read(1, masked=True).mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da8609-b43f-4555-950e-8a34681ab282",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudys = []\n",
    "for (region, year, month, dove), asset_ids in cloudy_downloads.items():\n",
    "    for asset_id in asset_ids:\n",
    "        key = (str(year), str(month), str(region), asset_id)\n",
    "        filename = ff.get(key)\n",
    "        if filename is None:\n",
    "            continue\n",
    "            # print((region, year, month, dove), asset_id)\n",
    "        cloudys.append({\n",
    "            \"region\": int(region),\n",
    "            \"year\": int(year),\n",
    "            \"month\": int(month),\n",
    "            \"instrument\": dove,\n",
    "            \"source_tif\": filename,\n",
    "            \"acquired\": parse_dt_from_asset_id(asset_id),\n",
    "            \"asset_id\": asset_id,\n",
    "        })\n",
    "\n",
    "cloudy_labels_df = pd.DataFrame(cloudys)\n",
    "print(len(cloudy_labels_df))\n",
    "cloudy_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4b088-7087-429b-96ab-e320bcb11be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cloudy_labels_df.iloc[82].source_tif\n",
    "with rasterio.open(a) as src:\n",
    "    plt.figure()\n",
    "    plt.imshow(false_color(src.read(), src.read(1, masked=True).mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5c8bb-1476-4a23-a2e9-a6983d9028c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6012a-dcd3-422e-9eee-e51a328597ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(v) for v in cloudy_downloads.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c85c8-d719-4c4d-930e-908caccd5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for (region, year, month, dove), cloudy in cloudy_downloads.items():\n",
    "    save_pth = Path(\"/Volumes/x10pro/estuary/ca_cloudy/\") / str(dove) / \"results\" / str(year) / str(month) / str(region) / \"cloudy_images_to_download.csv\"\n",
    "    save_pth.parent.mkdir(exist_ok=True, parents=True)\n",
    "    df = pd.DataFrame(cloudy, columns=[\"asset_id\"])\n",
    "    df['include_image'] = True\n",
    "    df.to_csv(save_pth, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680242d-e273-4e29-960e-74797532fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fd319-1fc0-4aed-a4c0-17bac01ddd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f5c24-dcfa-4cc6-a593-4e29531f99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(Path(\"/Volumes/x10pro/estuary/ca_all/dove/labels.csv\"))\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c8d4a-b2a8-4fd3-b9bc-e31139f6181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccc(pth):\n",
    "    pth = Path(pth)\n",
    "    with open(pth.parent.parent / \"filtered_search_results.json\") as f:\n",
    "        data = json.load(f)\n",
    "    dd = next(d for d in data if d[\"id\"] in pth.stem)\n",
    "    print(dd['properties'])\n",
    "    return\n",
    "ccc(labels.source_tif.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046f54e-802f-43de-89cf-02c00b8d76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_clear_percent(pth):\n",
    "    pth = Path(pth)\n",
    "    with open(pth.parent.parent / \"filtered_search_results.json\") as f:\n",
    "        data = json.load(f)\n",
    "    dd = next(d for d in data if d[\"id\"] in pth.stem)\n",
    "    print(dd['properties'])\n",
    "    return\n",
    "    return dd[\"properties\"][\"clear_percent\"]\n",
    "\n",
    "def scene_visible_percent(pth):\n",
    "    pth = Path(pth)\n",
    "    with open(pth.parent.parent / \"filtered_search_results.json\") as f:\n",
    "        data = json.load(f)\n",
    "    dd = next(d for d in data if d[\"id\"] in pth.stem)\n",
    "    return dd[\"properties\"][\"visible_percent\"]\n",
    "\n",
    "labels[\"scene_visible_percent\"] = labels.source_tif.apply(scene_visible_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320152a-bedc-441d-b12b-d9468c99a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clear_percent(pth):\n",
    "    pth = Path(pth)\n",
    "\n",
    "    key = \"_\".join(pth.stem.split(\"_\")[:2])\n",
    "    udm_pth = next(p for p in pth.parent.glob(\"*udm2_clip.tif\") if key in p.stem)\n",
    "\n",
    "    with rasterio.open(udm_pth) as src:\n",
    "        data = src.read([1, 7])\n",
    "    clear = data[0]\n",
    "    conf = data[-1]\n",
    "    nodata = conf < 1\n",
    "    yesdata = ~nodata\n",
    "    clear[nodata] = 0\n",
    "\n",
    "    pct = 100 * clear.sum() / yesdata.sum()\n",
    "    return pct\n",
    "\n",
    "labels[\"clear_percent\"] = labels.source_tif.apply(add_clear_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9c6b9-e666-4796-b98a-7c174a9d4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[\"unsure\"] = labels.label.apply(lambda a: int(a == \"unsure\"))\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2e4db-6576-4074-8ccb-5641dc0029f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    data=labels,\n",
    "    x=\"clear_percent\",\n",
    "    y=\"scene_visible_percent\",\n",
    "    hue=\"unsure\",\n",
    "    palette={0: \"steelblue\", 1: \"orange\"},\n",
    "    alpha=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc7e8f-d117-419e-b2dd-ac987184f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=labels,\n",
    "    x=\"scene_visible_percent\",\n",
    "    hue=\"unsure\",\n",
    "    bins=20,\n",
    "    stat=\"density\",  # or \"probability\"\n",
    "    common_norm=False,  # don't normalize across classes\n",
    "    palette={0: \"steelblue\", 1: \"orange\"},\n",
    "    alpha=0.6,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"scene_clear_percent\")\n",
    "plt.ylabel(\"Density (normalized per class)\")\n",
    "plt.title(\"Normalized distribution of scene_visible_percent by 'unsure' label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64400ff1-e7e0-4b1e-ac21-60f7e55bb15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=labels,\n",
    "    x=\"clear_percent\",\n",
    "    hue=\"unsure\",\n",
    "    bins=20,\n",
    "    stat=\"density\",  # or \"probability\"\n",
    "    common_norm=False,  # don't normalize across classes\n",
    "    palette={0: \"steelblue\", 1: \"orange\"},\n",
    "    alpha=0.6,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"clear_percent\")\n",
    "plt.ylabel(\"Density (normalized per class)\")\n",
    "plt.title(\"Normalized distribution of clear_percent by 'unsure' label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8203c-3296-44b7-8142-a7fe86a0c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrr(lll):\n",
    "    pcts = []\n",
    "    # for scene_visible_pct in range(0, 30, 1):\n",
    "    #     for scene_clear_pct in range(0, 30, 1):\n",
    "    for clear_pct in range(50, 110, 10):\n",
    "        cnts0 = len(lll[\n",
    "            (lll.unsure == 0)\n",
    "            & (\n",
    "                # (lll.scene_clear_percent < scene_clear_pct) | \n",
    "                (lll.scene_clear_percent < 10)\n",
    "                | (lll.clear_percent < clear_pct)\n",
    "            )\n",
    "        ])\n",
    "        cnts1 = len(lll[\n",
    "            (lll.unsure == 1)\n",
    "            & (\n",
    "                # (lll.scene_clear_percent < scene_clear_pct) | \n",
    "                (lll.scene_clear_percent < 10)\n",
    "                | (lll.clear_percent < clear_pct)\n",
    "            )\n",
    "        ])\n",
    "        pcts.append({\n",
    "            # \"scene_visible_pct\": scene_visible_pct,\n",
    "            \"clear_pct\": clear_pct,\n",
    "            # \"scene_clear_pct\": scene_clear_pct,\n",
    "            \"u0\": cnts0,\n",
    "            \"u1\": cnts1,\n",
    "            \"unsure_pct\": 100 * cnts1 / max(1, (cnts0 + cnts1))\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(pcts)\n",
    "\n",
    "a = rrr(labels)\n",
    "a.plot.scatter(y=\"unsure_pct\", x=\"u1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d2dde-8df6-460b-a7be-c76c8bbeaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a.unsure_pct > 30].sort_values([\"u1\", \"unsure_pct\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a27133-2d8a-4fe8-a6e1-774cbb1e9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data=labels[\n",
    "    (labels.scene_clear_percent > 10)\n",
    "    ],\n",
    "    x=\"clear_percent\",\n",
    "    hue=\"unsure\",\n",
    "    bins=20,\n",
    "    stat=\"density\",  # or \"probability\"\n",
    "    common_norm=False,  # don't normalize across classes\n",
    "    palette={0: \"steelblue\", 1: \"orange\"},\n",
    "    alpha=0.6,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"clear_percent\")\n",
    "plt.ylabel(\"Density (normalized per class)\")\n",
    "plt.title(\"Normalized distribution of clear_percent by 'unsure' label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c542d7-e40a-4c6c-9dda-7114309b7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[\n",
    "    (labels.scene_clear_percent >= 10)\n",
    "].plot.scatter(x=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554227b0-4317-4840-ac1d-64da94c89836",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, row = next(ii)\n",
    "print(Path(row.source_tif).stem)\n",
    "print(row)\n",
    "with rasterio.open(row.source_tif) as src:\n",
    "    data = src.read(out_dtype=np.float32)\n",
    "    nodata = ~src.read_masks(1)\n",
    "    if len(data) == 4:\n",
    "        img = false_color(data, nodata)\n",
    "    else:\n",
    "        img = broad_band(data, nodata)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bec989-e8de-47e9-b9b9-39ef001f3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "base = Path(\"/Users/kyledorman/data/results/estuary/train\")\n",
    "paths = list(base.glob(\"20251008*\")) + [sorted(list(base.glob(\"20251006*\")))[-1]]\n",
    "for pth in paths:\n",
    "    if not (pth / \"preds.csv\").exists():\n",
    "        continue\n",
    "    df = pd.read_csv(pth / \"preds.csv\")\n",
    "\n",
    "    with open(pth / \"cli_diff.yaml\") as f:\n",
    "        conf = yaml.safe_load(f)\n",
    "    if \"20251003\" in pth.name:\n",
    "        df[\"smooth_factor\"] = 0.0\n",
    "    else:\n",
    "        df[\"smooth_factor\"] = conf.get(\"smooth_factor\", 0.0)\n",
    "    df[\"perch_smooth_factor\"] = conf.get(\"perch_smooth_factor\", 0.0)\n",
    "    df[\"epochs\"] = conf.get(\"epochs\", 0)\n",
    "    df[\"model\"] = pth.name\n",
    "    runs.append(df)\n",
    "\n",
    "runs_df = pd.concat(runs, ignore_index=True)\n",
    "\n",
    "runs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa3071-5437-425a-8fd8-71715a1a1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_results = (\n",
    "    runs_df.sort_values(by=[\"region\", \"epochs\", \"perch_smooth_factor\", \"smooth_factor\"])\n",
    "    .groupby(by=[\"region\", \"model\", \"dataset\"], as_index=False)\n",
    "    .correct.mean()\n",
    "    .rename(columns={\"correct\": \"accuracy\"})\n",
    ")\n",
    "\n",
    "grouped_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1954035-ae9e-4cfa-b907-ab88669e5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 20))  # tall plot for 75 regions\n",
    "\n",
    "df = grouped_results.copy()\n",
    "df[\"region\"] = df.region.apply(str)\n",
    "\n",
    "# Boxplots for train per region\n",
    "sns.boxplot(\n",
    "    data=df[df[\"dataset\"] == \"train\"],\n",
    "    y=\"region\",\n",
    "    x=\"accuracy\",\n",
    "    color=\"lightblue\",\n",
    "    showfliers=False,\n",
    "    orient=\"h\",\n",
    "    label=\"Train\",\n",
    "    # color=\"lightblue\", marker=\"D\", s=30, label=\"Train\"\n",
    ")\n",
    "\n",
    "# Overlay val points\n",
    "sns.boxplot(\n",
    "    data=df[df[\"dataset\"] == \"val\"],\n",
    "    y=\"region\",\n",
    "    x=\"accuracy\",\n",
    "    color=\"lightgreen\",\n",
    "    showfliers=False,\n",
    "    orient=\"h\",\n",
    "    label=\"Val\",\n",
    "    # color=\"lightblue\", marker=\"D\", s=30, label=\"Train\"\n",
    ")\n",
    "\n",
    "# Overlay test points\n",
    "sns.boxplot(\n",
    "    data=df[df[\"dataset\"] == \"test\"],\n",
    "    y=\"region\",\n",
    "    x=\"accuracy\",\n",
    "    color=\"pink\",\n",
    "    showfliers=False,\n",
    "    orient=\"h\",\n",
    "    label=\"Val\",\n",
    ")\n",
    "\n",
    "plt.title(\"Accuracy distribution\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Region\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58ab83-3b03-4228-8366-7a197ea2246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = runs_df.groupby(\"region\").correct.mean()\n",
    "worst_regions = a.sort_values().iloc[:10].index.tolist()\n",
    "worst_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a665147-c00a-4323-bef6-e1a7786380dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    runs_df[runs_df.dataset != \"train\"]\n",
    "    .groupby([\"model\", \"region\"], as_index=False)\n",
    "    .correct.mean()\n",
    "    .rename(columns={\"correct\": \"accuracy\"})\n",
    ")\n",
    "a = df.groupby(\"region\").accuracy.min()\n",
    "worst_regions = a.sort_values().iloc[:10].index.tolist()\n",
    "\n",
    "adf = df[df.region.isin(worst_regions)].copy().sort_values(\"model\")\n",
    "adf[\"region\"] = adf.region.apply(str)\n",
    "\n",
    "sns.boxplot(\n",
    "    data=adf,\n",
    "    y=\"model\",\n",
    "    x=\"accuracy\",\n",
    "    color=\"lightblue\",\n",
    "    showfliers=False,\n",
    "    orient=\"h\",\n",
    "    label=\"Val\",\n",
    "    # color=\"lightblue\", marker=\"D\", s=30, label=\"Train\"\n",
    ")\n",
    "\n",
    "# sns.boxplot(\n",
    "#     data=df[df[\"dataset\"]==\"test\"],\n",
    "#     y=\"model\", x=\"accuracy\",\n",
    "#     color=\"pink\", showfliers=False, orient=\"h\", label=\"Test\"\n",
    "#     # color=\"lightblue\", marker=\"D\", s=30, label=\"Train\"\n",
    "# )\n",
    "\n",
    "# sns.boxplot(\n",
    "#     data=df[df[\"dataset\"]==\"train\"],\n",
    "#     y=\"model\", x=\"accuracy\",\n",
    "#     color=\"green\", showfliers=False, orient=\"h\", label=\"Train\"\n",
    "#     # color=\"lightblue\", marker=\"D\", s=30, label=\"Train\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc4f89-506a-4a47-a3d5-e5a3bd4ac3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_regions = pd.read_csv(\"/Volumes/x10pro/estuary/geos/skipped_regions.csv\")[\n",
    "    \"Site code\"\n",
    "].to_list()\n",
    "\n",
    "gdf = gpd.read_file(\"/Users/kyledorman/data/estuary/geos/ca_data_w_usgs.geojson\")\n",
    "gdf = gdf[~gdf[\"Site code\"].isin(skipped_regions)].copy()\n",
    "gdf = gdf.set_index(\"Site code\")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116bc7f-b9f0-4ba7-b010-6a0c570df0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pth = list(\n",
    "    Path(\"/Volumes/x10pro/estuary/skysat/results/\").glob(\"*/43/files/*pansharpened_clip.tif\")\n",
    ")[0]\n",
    "with rasterio.open(pth) as src:\n",
    "    data = src.read()\n",
    "    nodata = src.read(1, masked=True).mask\n",
    "    img = false_color(data, nodata)\n",
    "    img = Image.fromarray(img).resize((224, 224))\n",
    "    # .save(\"/Users/kyledorman/data/estuary/display/region_53.png\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe38812-67be-4e47-9a0c-3e06aab7bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Volumes/x10pro/estuary/dataset/normalization/stats.json\") as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "\n",
    "pt = PowerTransformer(standardize=False)\n",
    "pt.lambdas_ = np.array(stats[\"lambdas\"])\n",
    "st = StandardScaler()\n",
    "st.scale_ = np.array(stats[\"stds\"])\n",
    "st.mean_ = np.array(stats[\"means\"])\n",
    "\n",
    "norm = Pipeline([(\"PowerTransformer\", pt), (\"StandardScaler\", st)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e086b-b6e9-4d34-84d6-89e2280b2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = list(\n",
    "    Path(\"/Volumes/x10pro/estuary/skysat/results/\").glob(\"*/43/files/*pansharpened_clip.tif\")\n",
    ")[0]\n",
    "print(pth)\n",
    "with open(\"/Volumes/x10pro/estuary/dataset/normalization/stats.json\") as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "EIGHT_TO_4 = (7, 5, 3, 1)\n",
    "with rasterio.open(pth) as src:\n",
    "    data = src.read(out_dtype=np.float32)\n",
    "    nodata = src.read(1, masked=True).mask\n",
    "    rgb = masked_contrast_stretch(data[[2, 1, 0]], ~nodata)\n",
    "    plt.imshow(rgb.transpose((1, 2, 0)))\n",
    "\n",
    "    img = np.zeros((8, *data.shape[1:]), dtype=data.dtype)\n",
    "    for i, b in enumerate(reversed(EIGHT_TO_4)):\n",
    "        img[b] = data[i]\n",
    "    shp = img.shape\n",
    "    img = norm.transform(img.reshape(len(img), -1).T).T.reshape(shp)\n",
    "    img = np.array([img[i] for i in reversed(EIGHT_TO_4)])\n",
    "\n",
    "bgrnir = [\"B\", \"G\", \"R\", \"NIR\"]\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(img[i])\n",
    "    ax.set_title(bgrnir[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b4ec6-b6bd-4ac9-a2f7-d4330d7632ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pth = list(Path(\"/Volumes/x10pro/estuary/dove/results/\").glob(\"*/*/43/files/*SR*clip.tif\"))[0]\n",
    "with open(\"/Volumes/x10pro/estuary/dataset/normalization/stats.json\") as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "print(pth)\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "EIGHT_TO_4 = (7, 5, 3, 1)\n",
    "with rasterio.open(pth) as src:\n",
    "    data = src.read(out_dtype=np.float32)\n",
    "    nodata = src.read(1, masked=True).mask\n",
    "    rgb = masked_contrast_stretch(data[[2, 1, 0]], ~nodata)\n",
    "    # plt.imshow(rgb.transpose((1, 2, 0)))\n",
    "\n",
    "    img = np.zeros((8, *data.shape[1:]), dtype=data.dtype)\n",
    "    for i, b in enumerate(reversed(EIGHT_TO_4)):\n",
    "        img[b] = data[i]\n",
    "    shp = img.shape\n",
    "    img = norm.transform(img.reshape(len(img), -1).T).T.reshape(shp)\n",
    "    img = np.array([img[i] for i in reversed(EIGHT_TO_4)])\n",
    "\n",
    "bgrnir = [\"B\", \"G\", \"R\", \"NIR\"]\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(img[i])\n",
    "    ax.set_title(bgrnir[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa86977-7118-4d22-8fc3-903dfc8faa43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pth = list(Path(\"/Volumes/x10pro/estuary/superdove/results/\").glob(\"*/*/43/files/*SR*clip.tif\"))[1]\n",
    "with open(\"/Volumes/x10pro/estuary/dataset/normalization/stats.json\") as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "print(pth)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "with rasterio.open(pth) as src:\n",
    "    img = src.read(out_dtype=np.float32)\n",
    "    nodata = src.read(1, masked=True).mask\n",
    "    rgb = masked_contrast_stretch(img[[5, 3, 1]], ~nodata)\n",
    "    plt.imshow(rgb.transpose((1, 2, 0)))\n",
    "\n",
    "    shp = img.shape\n",
    "    img = norm.transform(img.reshape(len(img), -1).T).T.reshape(shp)\n",
    "\n",
    "from estuary.util.constants import BAND_NAMES\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(10, 20))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(img[i])\n",
    "    ax.set_title(BAND_NAMES[i])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd884f-cf49-4350-be92-0abf08c401e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_preds = pd.read_csv(\"/Volumes/x10pro/estuary/ca_all/preds.csv\")\n",
    "contig_preds[\"acquired\"] = contig_preds.source_tif.apply(lambda a: parse_dt_from_pth(Path(a)))\n",
    "contig_preds = contig_preds.sort_values(by=[\"region\", \"acquired\"])\n",
    "contig_preds[\"year\"] = contig_preds.acquired.dt.year\n",
    "contig_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325a832-725c-4f16-8b76-d03b7fc209f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_yr = (\n",
    "    contig_preds.groupby([\"year\", \"region\"], as_index=False)\n",
    "    .correct.mean()\n",
    "    .rename(columns={\"correct\": \"accuracy\"})\n",
    ")\n",
    "\n",
    "acc_yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81961e-ec91-4b08-9f24-fa222a814cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_yr.region.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99deab8c-ac2c-4316-87a7-85ed0abce920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "for region, group in acc_yr.groupby(\"region\"):\n",
    "    group = group.sort_values(\"year\")\n",
    "    ax.plot(group[\"year\"], group[\"accuracy\"], marker=\"o\", label=region)\n",
    "\n",
    "ax.set_title(\"Accuracy Over Time by Region\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.legend(title=\"Region\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e925ec-2510-419b-a3da-750b550368a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=acc_yr, x=\"year\", y=\"accuracy\", color=\"skyblue\", width=0.6)\n",
    "plt.title(\"Accuracy per Year (All Regions Combined)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0653b-40fb-426b-83a5-cb3f5c716c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
